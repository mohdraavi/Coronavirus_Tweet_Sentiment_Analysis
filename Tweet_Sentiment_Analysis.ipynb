{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "NC_X3p0fY2L0",
        "q29F0dvdveiT",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Coronavirus Tweet Sentiment Analysis\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Project by Mohd Ravi** \n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Classification project, our aim to predict correct sentiment of a tweet from the data.\n",
        "* Dataset Loading\n",
        "* Dataset Information\n",
        "* Checking Duplicates\n",
        "* Understanding Variable.\n",
        "* Data Wrangling\n",
        "* Story telling with several kind of charts like barplot,heatmap,pie chart,wordcloud,pairplot.\n",
        "* Feature Engineering like Handling missing values\n",
        "* Text Preprocessing like Removing users name,expand contraction,lower casing,removing punctuation,removing urls and digits,removing stopwords & white spaces, removing accent words,removing hashtags,tokenization,text normalization,pos,text vectorization\n",
        "* Data transformation\n",
        "* Data Splitting\n",
        "* checking for imbalanced class\n",
        "* Training different models such as: \n",
        "\n",
        "1 . Logistic Regression\n",
        "\n",
        "2 . Stochastic Gradient Descent\n",
        "\n",
        "3 . Multinomial naive bayes"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/mohdraavi/Coronavirus_Tweet_Sentiment_Analysis"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a classification model to predict the sentiment of covid-19 tweets.**\n",
        "\n",
        "\n",
        "**Determine Sentiment(Negative,Positive and Neutral) Tweets which posted during Covid 19 (2020).**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "from numpy import loadtxt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib import rcParams\n",
        "from datetime import *\n",
        "import warnings\n",
        "\n",
        "# Ignore warning messages\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import stemming and lemmatizing libraries from NLTK\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "# Import vectorization libraries from scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Import image-related libraries\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "# Import evaluation metrics from scikit-learn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Import logistic regression model from scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "rXUeZzUe5uM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mTk4AhY_sVVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "import unidecode\n"
      ],
      "metadata": {
        "id": "dsd1hqwTvaAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Coronavirus Tweets.csv',encoding='latin-1')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f'Number of Rows : {df.shape[0]}')\n",
        "print(f'Number of columns : {df.shape[1]}')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(),cmap='plasma',annot=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* There are 41157 rows and 6 columns.\n",
        "* Feature like Location has null values.\n",
        "* There is no duplicate values i.e: 41157 unique values.\n",
        "* All features have object data types except username and screenname."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* UserName - CodedUsername\n",
        "* ScreenName - CodedScreenname\n",
        "* Location - Region of origin\n",
        "* TweetAt - Tweet Timing\n",
        "* OriginalTweet - Frist tweet in the thread\n",
        "* Sentiment - Sentiment of the tweet(target)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking unique values in Sentiment\n",
        "df['Sentiment'].unique()"
      ],
      "metadata": {
        "id": "hed-pihy3DsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TweetAt'].head()"
      ],
      "metadata": {
        "id": "ul31-ASy5jD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#copy original dataset just to preserve original\n",
        "data = df.copy()"
      ],
      "metadata": {
        "id": "VxtXGrl_eENm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.rename(columns={'TweetAt':'Date'},inplace=True)"
      ],
      "metadata": {
        "id": "tDeDhMQEea5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Date variable into date_time type\n",
        "data['Date'] = pd.to_datetime(data['Date'])"
      ],
      "metadata": {
        "id": "cE8Ku2O5eVlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting month and year and storing in another variable\n",
        "data['month'] = pd.DatetimeIndex(data['Date']).month"
      ],
      "metadata": {
        "id": "C_cRix_Xeg9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in which month the most number of tweet was made\n",
        "month_df=pd.DataFrame(data.groupby(['month'])['OriginalTweet'].count().reset_index().sort_values(['OriginalTweet'],ascending=False).rename(columns={'OriginalTweet':'Count'}))\n",
        "month_df"
      ],
      "metadata": {
        "id": "N555z6B1e18a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "locatoin_count_df=pd.DataFrame(df.groupby(['Location'])['OriginalTweet'].count().reset_index().sort_values(by='OriginalTweet',ascending=False).rename(columns={'OriginalTweet':'Count'}))\n",
        "locatoin_count_df"
      ],
      "metadata": {
        "id": "mvrTC4z3VbH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_count_df = pd.DataFrame(data['Sentiment'].value_counts().reset_index().rename(columns={'index':'Sentiment','Sentiment':'Count'}))\n",
        "sentiment_count_df"
      ],
      "metadata": {
        "id": "i_JqPWhacIMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Converted Date type to datetime type\n",
        "* cheked month wise tweet count\n",
        "* checked from which location most no. tweets were made\n",
        "* we also saw each "
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 Most Tweeted Months"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#checking which month is most tweeted\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(data=month_df,x='month',y='Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check which month is most tweeted"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Month 3 (March ) is the most tweeted month"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 "
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#countplot of sentiment in each month\n",
        "plt.figure(figsize=(12,7))\n",
        "sns.countplot(data=data,x='month',hue='Sentiment')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1QoEbQS1pAgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ccN3AZ0MpOF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check most tweet in each month sentiment wise."
      ],
      "metadata": {
        "id": "Bsp4Yx-CpOF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chart - 3"
      ],
      "metadata": {
        "id": "np7nEyK5psUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#from which location most no. of tweets were made\n",
        "plt.figure(figsize=(16,7))\n",
        "sns.barplot(data=locatoin_count_df[:10],x='Location',y='Count')\n",
        "plt.title('Top 10 countres with most tweeted')\n",
        "plt.xlabel('Country Name')\n",
        "plt.ylabel('No. of tweets')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to check from which location the most no. of tweets were posted"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most tweets were tweeted from London,United state,London England."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#plotting pie chart for sentiments\n",
        "d = sentiment_count_df['Count'].tolist()\n",
        "label = sentiment_count_df['Sentiment'].tolist()\n",
        "plt.pie(d,labels=label,colors = sns.color_palette('pastel'),autopct='%.0f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see which type of sentiments were the most."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have seen in pie chart positive sentiment is the most and followed by Negative"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#countries with most negative tweets\n",
        "neg_df = data[(data['Sentiment']=='Negative') | (data['Sentiment']=='Extremely Negative')]\n",
        "plt.figure(figsize=(12,6))\n",
        "neg_df['Location'].value_counts().head(20).plot(kind='bar',color = sns.color_palette(\"husl\"),width=0.7)\n",
        "plt.title(\" Top 20 Country have Negative Tweeted Most \", fontsize = 10)\n",
        "plt.xlabel('Country', fontsize = 12)\n",
        "plt.ylabel('Tweet ', fontsize = 12)\n",
        "plt.xticks(rotation=60)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from which country the most number of negatives reviews were made."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most no negative were posted from London"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#countries with most positive tweets\n",
        "Pos_df = data[(data['Sentiment']=='Positive') | (data['Sentiment']=='Extremely Positive')]\n",
        "plt.figure(figsize=(12,6))\n",
        "Pos_df['Location'].value_counts().head(20).plot(kind='bar',color = sns.color_palette(\"husl\"),width=0.7)\n",
        "plt.title(\" Top 20 Countres with  Most  positive Tweets \", fontsize = 10)\n",
        "plt.xlabel('Country', fontsize = 12)\n",
        "plt.ylabel('Tweet ', fontsize = 12)\n",
        "plt.xticks(rotation=60)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from which country the most number of positive reviews were made"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most number of positive reviews were posted from United state"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for Extract #tags \n",
        "def ext_hashtag(t):\n",
        "  return [i for i in t.split() if '#' in i]\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply above function \n",
        "data['hastag']=data['OriginalTweet'].apply(ext_hashtag)\n"
      ],
      "metadata": {
        "id": "5Gu-o_GM4W6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count every hashtags from Counter dependency \n",
        "from collections import Counter\n",
        "d = Counter(data.hastag.sum())\n",
        "hashtags= pd.DataFrame([d]).T.reset_index()\n"
      ],
      "metadata": {
        "id": "-ITG52JT4Z4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename COlumn name\n",
        "hashtags.rename(columns = {'index':'Hashtags',0:'Count'}, inplace = True)"
      ],
      "metadata": {
        "id": "afqjG9YN4fCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort data frame\n",
        "top_hashtags=hashtags.sort_values(by='Count',ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "S8C0qJ4y4iEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plot of Most used hashtags\n",
        "plt.rcParams[\"figure.figsize\"]=(10,6)\n",
        "\n",
        "ax=top_hashtags.head(20).plot(kind='bar',\n",
        "                           x='Hashtags',\n",
        "                           color = sns.color_palette(\"husl\"),\n",
        "                           width=0.8\n",
        "                           )\n",
        "plt.xticks(rotation=70)\n",
        "plt.title(\" Top 20 most used #tags \", fontsize = 10)\n",
        "plt.xlabel('#tags', fontsize = 12)\n",
        "plt.ylabel('Count ', fontsize = 12)\n",
        "\n",
        "\n",
        "#Patches Height \n",
        "for p in ax.patches:\n",
        "  x = p.get_x() + p.get_width() / 2 - 0.4\n",
        "  y = p.get_y() + p.get_height() \n",
        "  ax.annotate(p.get_height(),(x,y) ,size = 8)\n"
      ],
      "metadata": {
        "id": "UO1KvM_i4p3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "freq_dict=dict(zip(hashtags['Hashtags'].tolist(),hashtags['Count'].tolist()))\n",
        "word = WordCloud(width=900,height=400,max_words=200,background_color='black').generate_from_frequencies(freq_dict)\n",
        "plt.figure(figsize=(14, 12))\n",
        "plt.imshow(word, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Most used user name in tweets\n",
        "def ext_name(text):\n",
        "  return [i for i in text.split() if '@' in i ]"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['User_Name']=data['OriginalTweet'].apply(ext_name)"
      ],
      "metadata": {
        "id": "WzkxmBa47mWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count every username from Counter dependency \n",
        "\n",
        "from collections import Counter\n",
        "cnt= Counter(data.User_Name.sum())\n",
        "\n",
        "#dataframe of username and value count\n",
        "usrnam= pd.DataFrame([cnt]).T.reset_index()\n"
      ],
      "metadata": {
        "id": "zcErEvlm8YZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename Column name\n",
        "usrnam.rename(columns = {'index':'User_name',0:'Count'}, inplace = True)"
      ],
      "metadata": {
        "id": "6YrNTkOZ8uPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sorted by descending order\n",
        "top_username=usrnam.sort_values(by='Count',ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "PwN7h4Ht8ySr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plot of Most used @username\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"]=(11,6)\n",
        "\n",
        "ax=top_username.head(20).plot(kind='bar',\n",
        "                           x='User_name',\n",
        "                           color = sns.color_palette(\"husl\"),\n",
        "                           width=0.8\n",
        "                           )\n",
        "plt.xticks(rotation=70)\n",
        "\n",
        "#Patcches height\n",
        "for p in ax.patches:\n",
        "  x = p.get_x() + p.get_width() / 2 - 0.4\n",
        "  y = p.get_y() + p.get_height() \n",
        "  ax.annotate(p.get_height(),(x,y) ,size = 8)\n"
      ],
      "metadata": {
        "id": "8_FuIO7J87I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Chart - 10"
      ],
      "metadata": {
        "id": "VvKBetrLvWbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Wordcloud image of @username, showing highlight most used and low least used.\n",
        "\n",
        "# dictionary of hashtags and his value counts\n",
        "wcloud_data_user = dict(zip(usrnam['User_name'].tolist(), usrnam['Count'].tolist()))\n",
        "\n",
        "# generate image\n",
        "wcloud = WordCloud(width=800, height=400, max_words=200,background_color = 'black').generate_from_frequencies(wcloud_data_user)\n",
        "plt.figure(figsize=(14, 12))\n",
        "plt.imshow(wcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UFUOpSqQ9RR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12,10))   \n",
        "sns.heatmap(data.corr(),cmap=\"Spectral\", cbar_kws={'shrink': .6}, square=True, annot=True, fmt='.2f', linewidths=0.8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(data)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Location'].fillna(method=\"ffill\",limit=1,inplace=True)"
      ],
      "metadata": {
        "id": "2d9uU1hs0gRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.Location.isnull().sum()"
      ],
      "metadata": {
        "id": "6DnPCqzf0iEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Location'].fillna(method=\"bfill\",limit=1,inplace=True)\n",
        "data.Location.isnull().sum()"
      ],
      "metadata": {
        "id": "NDLJWRQl0msK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Location'].mode()"
      ],
      "metadata": {
        "id": "3hDIpotJ0zr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remain nan value fiil by most frequent value\n",
        "data['Location'].fillna('London',inplace=True)\n",
        "data['Location'].isnull().sum()"
      ],
      "metadata": {
        "id": "FzbnQAXj02gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We used ffill, bfill and mode value of this data because it is catagorical column"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Removing Users Name"
      ],
      "metadata": {
        "id": "GgrpbgOd4Z4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_name(text):\n",
        "  return \" \".join([i for i in text.split() if '@' not in i])"
      ],
      "metadata": {
        "id": "_4wbzRd64Awo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['OriginalTweet'].apply(remove_name)"
      ],
      "metadata": {
        "id": "iFDzAXYP4-PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "Gc6IG-pB6QIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand Contraction\n",
        "import contractions\n",
        "data['Tweets'] = data['Tweets'].apply(lambda x : contractions.fix(x))"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "def lower(text):\n",
        "  return \" \".join([i.lower() for i in text.split()])"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['Tweets'].apply(lower)"
      ],
      "metadata": {
        "id": "TfQEHAkW7g3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "def remove_punc(data):\n",
        "  translator = str.maketrans('', '', string.punctuation)\n",
        "  return data.translate(translator)"
      ],
      "metadata": {
        "id": "mcIC6Zgy8Ow7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['Tweets'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "5VG2e5An9z-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "#remove urls\n",
        "data['Tweets'] = data['Tweets'].apply(lambda x :re.sub(r'http\\S+',\"\",x))\n",
        "#removing digits\n",
        "data['Tweets'] = data['Tweets'].apply(lambda x : re.sub(r\"\\d+\",\"\",x))"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "sb6DguihtVXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw = stopwords.words('english')"
      ],
      "metadata": {
        "id": "6Wg3NkwBs48t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "def remvove_stopwords(text):\n",
        "  '''a function for removing the stopword'''\n",
        "  # removing the stop words and lowercasing the selected words\n",
        "  text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "  # joining the list of words with space separator\n",
        "  return \" \".join(text)"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['Tweets'].apply(remvove_stopwords)"
      ],
      "metadata": {
        "id": "uEH5VJi3th8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "def space_rem(text):\n",
        "    text = [word.strip() for word in text.split()]\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['Tweets'].apply(space_rem)"
      ],
      "metadata": {
        "id": "X0XsPNcFt40J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Removing Accents from Words"
      ],
      "metadata": {
        "id": "hVliJWdbuADl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function for remove accents from words\n",
        "def remove_accents(text):\n",
        "  return \" \".join([unidecode.unidecode(i) for i in text.split()])\n",
        "  "
      ],
      "metadata": {
        "id": "pBg6jrI9uKyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['Tweets'].apply(remove_accents)\n"
      ],
      "metadata": {
        "id": "Poa2FkMbuN2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####8. Remove Hashtag"
      ],
      "metadata": {
        "id": "0cTt0_W1ubmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function for remove hashtags\n",
        "def remove_hash(text):\n",
        "  l=[]\n",
        "  for i in text.split():\n",
        "    if '#' not in i:\n",
        "      l.append(i)\n",
        "    else:\n",
        "      l.append(i.replace(\"#\", \"\"))\n",
        "  return ' '.join(l)   "
      ],
      "metadata": {
        "id": "taDvrteJuTS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tweets'] = data['Tweets'].apply(remove_hash)\n"
      ],
      "metadata": {
        "id": "_JFEye44uUF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "ZH557txwvB5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "data['Tweets'] = data['Tweets'].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "fZsNlCO3vUpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Create a lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmatized_tokens = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Lemmatize the 'Review' column\n",
        "data['Tweets'] = data['Tweets'].apply(lemmatize_tokens)\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "#nltk.download('averaged_perceptron_tagger')\n",
        "#def pos(text):\n",
        "#  text=nltk.pos_tag(text)\n",
        "#  return text"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#i am not doing pos here becase its not giving good result"
      ],
      "metadata": {
        "id": "mw17yzZj32gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['text']=data['Tweets'].apply(pos)"
      ],
      "metadata": {
        "id": "B4-aHLyywAi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(0,len(data)):\n",
        "  review=data['Tweets'][i]\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "c8rbuYAxE3t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:10]"
      ],
      "metadata": {
        "id": "YzJZtXSHFuZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import numpy as npy\n",
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "response = requests.get(\"https://res.cloudinary.com/maxie/image/upload/v1617197755/TEMP/covid_ywd7ph.jpg\")\n",
        "image_bytes = io.BytesIO(response. content)\n",
        "dataset = \" \".join(corpus)\n",
        "def create_word_cloud(string):\n",
        "\n",
        "    maskArray = npy.array(Image.open(image_bytes))\n",
        "    cloud = WordCloud(background_color = \"black\", max_words = 150, mask = maskArray, stopwords = set(STOPWORDS),contour_width=1, contour_color='#333')\n",
        "    cloud.generate(string)\n",
        "#     cloud.to_file(\"wordCloud.png\")\n",
        "    return cloud\n",
        "dataset = dataset.lower()\n",
        "wordcloud=create_word_cloud(dataset)\n",
        "plt.figure(figsize=[20,10])\n",
        "plt.imshow(wordcloud) # image show\n",
        "plt.axis('off') # to off the axis of x and y\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6XS2Ul2RGBaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "metadata": {
        "id": "rbslq35w7z2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "count_vectorizer = CountVectorizer()\n",
        "count_vectorizer.fit_transform(data['Tweets'])"
      ],
      "metadata": {
        "id": "LCvy9HaN2SiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# already have done"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "data.drop(['UserName','ScreenName'],axis =1,inplace=True)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "QB45CMag96XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns.tolist()"
      ],
      "metadata": {
        "id": "CyZ-znOX-WrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "def senti_anal(val):\n",
        "  if (val=='Positive') | (val=='Extremely Positive'):  \n",
        "    return 'Positive'\n",
        "  elif (val=='Negative') | (val=='Extremely Negative'):\n",
        "    return 'Negative'\n",
        "  else:\n",
        "    return 'Neutral' "
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sentiment']=data['Sentiment'].apply(senti_anal)"
      ],
      "metadata": {
        "id": "G_kak3vV-8T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sentiment'].unique()"
      ],
      "metadata": {
        "id": "zy8eayIn_B6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "x=data['Tweets']\n",
        "y=data['Sentiment']"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y ,test_size=0.2, random_state = 42, stratify = y)\n",
        "print(x_train.shape)                                   \n",
        "print(x_test.shape )"
      ],
      "metadata": {
        "id": "ghqi0ghR_iuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used 80:20 splitting ratio because this is considered best split ratio. \n",
        "\n",
        "That is 80% of the dataset goes into the training set and 20% of the dataset goes into the testing set."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "data['Sentiment'].value_counts().plot(kind='pie',\n",
        "                                         fontsize=15,\n",
        "                                         autopct=\"%0.1f%%\",\n",
        "                                         labels=data['Sentiment'].value_counts().index,\n",
        "                                         explode=[0.01,0.04,0.09],\n",
        "                                         colors = sns.color_palette(\"husl\"),\n",
        "                                         shadow=True\n",
        "                                         )"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "#fit value\n",
        "x_train_vectorized=count_vectorizer.fit_transform(x_train)\n",
        "x_test_vectorized =count_vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "5XZqND8y4T02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mod_evaluat(model, true, predicted):\n",
        "  \n",
        "  \"\"\"Function which gives output of the model implimentation on train \n",
        "     and test set (Used as Output Display) \"\"\"\n",
        "\n",
        "  train_accuracy = model.score(x_train_vectorized, y_train)\n",
        "  test_accuracy = accuracy_score(true, predicted)\n",
        "  report = classification_report(predicted, true)\n",
        "\n",
        "  print(model,'\\n')\n",
        "  print('Train Accuracy: ',round((train_accuracy), 2)*100,'%')\n",
        "  print('Test Accuracy: ',round((test_accuracy), 2)*100,'%')\n",
        "  print('Model Report: \\n', report)\n",
        "  "
      ],
      "metadata": {
        "id": "llENrtUb42_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(model, true, predicted):\n",
        "  print('-'*40)\n",
        "  print('Confusion Matrix: \\n')\n",
        "  cm = confusion_matrix(true, predicted)\n",
        "  cm = cm / np.sum(cm, axis = 1)[:,None]\n",
        "  labels = y.unique()\n",
        "  sns.set(rc={'figure.figsize':[5,4]})\n",
        "  sns.heatmap(cm, xticklabels = labels,\n",
        "            yticklabels = labels, \n",
        "            annot=True, \n",
        "            cmap = 'YlGnBu')\n",
        "  plt.show()\n",
        "  plt.pause(0.05)"
      ],
      "metadata": {
        "id": "FJ1tfsLw6VkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function compute test accuracy for comparison\n",
        "from sklearn.metrics import f1_score\n",
        "def mod_comp(model, true, predicted):\n",
        "  test_accur= accuracy_score(true, predicted)\n",
        "  f1_scor = f1_score(true, predicted,average='weighted')\n",
        "  report = classification_report(predicted, true) \n",
        "  return test_accur,f1_scor\n",
        "  "
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "LogReg = LogisticRegression()\n",
        "# Fit the Algorithm\n",
        "LogReg.fit(x_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "LogReg_prediction = LogReg.predict(x_test_vectorized)\n",
        "# Report"
      ],
      "metadata": {
        "id": "Ti7_VLhRB6Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mod_evaluat(LogReg, y_test, LogReg_prediction)\n",
        "conf_matrix(LogReg, y_test, LogReg_prediction)"
      ],
      "metadata": {
        "id": "2fyyGZ0WC0kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Actual vs Predict Values\n",
        "act_vs_pred=pd.DataFrame({\"actual\":y_test,\"prediction\": LogReg_prediction})\n",
        "act_vs_pred[:20]"
      ],
      "metadata": {
        "id": "sKZaIZYPEuJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "Logreg_cv = LogisticRegression()\n",
        "\n",
        "parameters = dict(penalty=['l1', 'l2'],C=[100, 10, 1.0, 0.1, 0.01,0.01])\n",
        "\n",
        "\n",
        "#Hyperparameter tuning by GridserchCV\n",
        "logreg_Gcv=GridSearchCV(Logreg_cv,parameters,cv=5)\n",
        "\n",
        "\n",
        "#fitting the data to model\n",
        "%time logreg_Gcv.fit(x_train_vectorized, y_train)\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "lgcv_pred=logreg_Gcv.predict(x_test_vectorized)\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation Chart of model\n",
        "mod_evaluat(logreg_Gcv.best_estimator_, y_test, lgcv_pred)\n",
        "conf_matrix(logreg_Gcv.best_estimator_, y_test, lgcv_pred)"
      ],
      "metadata": {
        "id": "4RajMOM2F_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Best estimator or model : ',logreg_Gcv.best_estimator_)\n",
        "print(\"\\nThe best fit parameters value is found out to be : \" ,logreg_Gcv.best_params_)\n",
        "print( \"\\n the average of all the cross-validation fold : \", logreg_Gcv.best_score_)"
      ],
      "metadata": {
        "id": "CVYuKGLwGDVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8mAB0bLGS1d"
      },
      "source": [
        "I used Grid Search CV optimization technique because GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Evaluation metric Score Chart (Base model)\\n')\n",
        "mod_evaluat(LogReg, y_test, LogReg_prediction)\n",
        "print('-'*40,'\\n Evaluation metric Score Chart with Hyperparameter tuning technique\\n')\n",
        "mod_evaluat(logreg_Gcv.best_estimator_, y_test, lgcv_pred)"
      ],
      "metadata": {
        "id": "abmeGzdJGpa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see there is no difference between"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "SGDClassifier_model = SGDClassifier(max_iter = 10000)\n",
        "SGDClassifier_model.fit(x_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "SGDC_prediction = SGDClassifier_model.predict(x_test_vectorized)\n",
        "\n",
        "# Report"
      ],
      "metadata": {
        "id": "P8BOC5wBPSFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mod_evaluat(SGDClassifier_model, y_test, SGDC_prediction)\n",
        "conf_matrix(SGDClassifier_model, y_test, SGDC_prediction)"
      ],
      "metadata": {
        "id": "Yk9JvSvMX3hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "sgdc_cv = SGDClassifier()\n",
        "parameters = dict(penalty=['l1', 'l2'],alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] )\n",
        "\n",
        "#Hyperparameter tuning by GridserchCV\n",
        "sgdc_Rcv=RandomizedSearchCV(estimator=sgdc_cv,param_distributions=parameters,  \n",
        "                              verbose=1, n_jobs=-1, n_iter=1000) \n",
        "\n",
        "#fitting the data to model\n",
        "%time sgdc_Rcv.fit(x_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "sgdcr_pred=sgdc_Rcv.predict(x_test_vectorized)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mod_evaluat(sgdc_Rcv.best_estimator_, y_test, sgdcr_pred)\n",
        "conf_matrix(sgdc_Rcv.best_estimator_, y_test, sgdcr_pred)"
      ],
      "metadata": {
        "id": "wXjHuwzxasjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Best estimator : ',sgdc_Rcv.best_estimator_)\n",
        "print(\"\\nThe best fit alpha value is found out to be :\" ,sgdc_Rcv.best_params_)\n",
        "print( \"\\n the average of all the cross-validation fold : \", sgdc_Rcv.best_score_)"
      ],
      "metadata": {
        "id": "ZjfR-Aa9a-Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Random Search CV because RandomizedSearchCV randomly passes the set of hyperparameters and calculate the score and gives the best set of hyperparameters which gives the best score as an output."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Evaluation metric Score Chart (Base model)\\n')\n",
        "mod_evaluat(SGDClassifier_model, y_test, SGDC_prediction)\n",
        "print('-'*40,'\\n Evaluation metric Score Chart with Hyperparameter technique\\n')\n",
        "mod_evaluat(sgdc_Rcv.best_estimator_, y_test, sgdcr_pred)"
      ],
      "metadata": {
        "id": "GockKwEibZZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "mnb = MultinomialNB()\n",
        "#Fit the Algorithm\n",
        "mnb.fit(x_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "mnb_pred = mnb.predict(x_test_vectorized)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mod_evaluat(mnb, y_test, mnb_pred)\n",
        "conf_matrix(mnb, y_test, mnb_pred)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],\n",
        "          'fit_prior': [True, False]\n",
        "         }\n",
        "# Fit the Algorithm\n",
        "\n",
        "multinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
        "multinomial_nb_grid.fit(x_train_vectorized, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "nb_pred_cv=multinomial_nb_grid.predict(x_test_vectorized)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "mod_evaluat(multinomial_nb_grid.best_estimator_, y_test, nb_pred_cv)\n",
        "conf_matrix(multinomial_nb_grid.best_estimator_, y_test, nb_pred_cv)"
      ],
      "metadata": {
        "id": "3A0zxQONhd3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Best estimator : ',multinomial_nb_grid.best_estimator_)\n",
        "print(\"\\nThe best fit alpha value is found out to be :\" ,multinomial_nb_grid.best_params_)\n",
        "print( \"\\nthe average of all the cross-validation fold : \", multinomial_nb_grid.best_score_)"
      ],
      "metadata": {
        "id": "JEcLOPkqwEDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Grid Search CV optimization technique because GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J2d3IdwxQtl"
      },
      "outputs": [],
      "source": [
        "print(' Evaluation metric Score Chart (Base model)\\n')\n",
        "mod_evaluat(mnb, y_test,mnb_pred)\n",
        "print('-'*40,'\\n Evaluation metric Score Chart with Hyperparameter technique\\n')\n",
        "mod_evaluat(multinomial_nb_grid.best_estimator_, y_test, nb_pred_cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Models Comparision"
      ],
      "metadata": {
        "id": "vfFt3AYayaOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison of accuracy, and f1_score of Models \n",
        "logreg_acc , logreg_f1 = mod_comp(LogReg, y_test, LogReg_prediction)\n",
        "\n",
        "logregCV_acc , logregCV_f1 = mod_comp(logreg_Gcv.best_estimator_, y_test, lgcv_pred)\n",
        "\n",
        "sgdc_acc , sgdc_f1 = mod_comp(SGDClassifier_model, y_test, SGDC_prediction)\\\n",
        "\n",
        "sgdcCV_acc , sgdcCV_f1 = mod_comp(sgdc_Rcv.best_estimator_, y_test, sgdcr_pred)\n",
        "\n",
        "naiveb_acc , naiveb_f1 = mod_comp(mnb, y_test, mnb_pred)\n",
        "\n",
        "naivebCV_acc , naivebCV_f1 = mod_comp(multinomial_nb_grid.best_estimator_, y_test, nb_pred_cv)"
      ],
      "metadata": {
        "id": "SwHFgbpfyfeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_df = pd.DataFrame(\n",
        "    {'Models': ['Logistic Regression','SGDClassifier','Naive Bayes Classifier','Logistic Regression on CV','SGDClassifier on CV','Naive_BC on CV'],\n",
        "     'Test Accuracy': [logreg_acc, sgdc_acc, naiveb_acc,logregCV_acc,sgdcCV_acc,naivebCV_acc],\n",
        "     'F1 Score' : [logreg_f1, sgdc_f1, naiveb_f1,logregCV_f1,sgdcCV_f1,naivebCV_f1]\n",
        "    })\n",
        "models_df.sort_values(by=['Test Accuracy'], ascending=False, inplace=True)\n",
        "models_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "k5yeRv9nyoJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is best evaluation metric to business impact because 'Accuracy' get answer the question, what percent of the models predictions were correct."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SGDClassifier**  is best model from above created because it have highest Accuracy And F1_score.\n",
        "\n",
        "And even in Cross-Validation & Hyperparameter Tuning technique **SGDClassifier** have higghest accuracy."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "# import pickle\n",
        "\n",
        "#serialized_model = pickle.dumps(SGDClassifier_model)\n",
        "# Save the model to a file\n",
        "#with open('best_model.pkl', 'wb') as file:\n",
        "#    file.write(serialized_model)"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Most tweeted month was march this dataset was year of 2020.\n",
        "* Most Number of tweets were made from London and United State.\n",
        "* most negative tweets were  made from London and Positive from United State.\n",
        "* Treding hashtags were #coronavirus,COVID19.\n",
        "* @realDonaldTrump and @Tesco were the most tagged and active users on the twitter.\n",
        "* High Frequent words in the data are coronavirus,supermarket,grocery store,sanitizer,people,\n",
        "* CounVectorizer used for vectorization.which Convert a collection of raw documents to vector of term/token counts.\n",
        "* For a Multiclass Classification, Out of all the models SGDClassifier is the best performing model with  82% accuracy. After which, Increase to 1% when hyper-tuned with RandomSearchCV.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}